{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04_newdata_inference — New Data Inference with CNN Fallback\n",
    "_Generated 2025-10-04_\n",
    "\n",
    "This notebook demonstrates inference on new data using the trained CNN model, with automatic fallback to an existing model if the CNN model is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Check device availability\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Load Model with Fallback Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn_model(model_path='artifacts/cnn1d.pt', calibrator_path='artifacts/calibrator.joblib'):\n",
    "    \"\"\"Load CNN model and calibrator if available.\"\"\"\n",
    "    model = None\n",
    "    calibrator = None\n",
    "    \n",
    "    # Try to load CNN model\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            from app.models.cnn1d import make_model\n",
    "            model = make_model()\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(f\"✓ CNN model loaded from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load CNN model: {e}\")\n",
    "            model = None\n",
    "    else:\n",
    "        print(f\"✗ CNN model not found at {model_path}\")\n",
    "    \n",
    "    # Try to load calibrator\n",
    "    if os.path.exists(calibrator_path):\n",
    "        try:\n",
    "            calibrator = joblib.load(calibrator_path)\n",
    "            print(f\"✓ Calibrator loaded from {calibrator_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load calibrator: {e}\")\n",
    "    else:\n",
    "        print(f\"✗ Calibrator not found at {calibrator_path}\")\n",
    "    \n",
    "    return model, calibrator\n",
    "\n",
    "def load_fallback_model():\n",
    "    \"\"\"Load fallback model (e.g., traditional ML model).\"\"\"\n",
    "    # Placeholder for loading an alternative model\n",
    "    # This could be a scikit-learn model, XGBoost, etc.\n",
    "    print(\"⚠ Loading fallback model (mock implementation)\")\n",
    "    return lambda x: np.random.random(len(x) if hasattr(x, '__len__') else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "cnn_model, calibrator = load_cnn_model()\n",
    "fallback_model = None\n",
    "\n",
    "if cnn_model is None:\n",
    "    print(\"\\n⚠ CNN model not available, using fallback model\")\n",
    "    fallback_model = load_fallback_model()\n",
    "    use_cnn = False\n",
    "else:\n",
    "    print(\"\\n✓ Using CNN model for inference\")\n",
    "    use_cnn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Generate Synthetic Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_lightcurve(has_transit=True, n_points=2048, seed=42):\n",
    "    \"\"\"Generate synthetic light curve for testing.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    period = 2.5\n",
    "    t0 = 0.5\n",
    "    duration = 0.08\n",
    "    \n",
    "    t = np.linspace(0, period * 5, n_points)\n",
    "    y = np.ones_like(t)\n",
    "    \n",
    "    if has_transit:\n",
    "        depth = 0.0015\n",
    "        phase = ((t - t0) / period) % 1.0\n",
    "        in_transit = phase < (duration / period)\n",
    "        y[in_transit] -= depth\n",
    "    \n",
    "    # Add noise\n",
    "    y += rng.normal(0, 0.0005, size=y.shape)\n",
    "    \n",
    "    return t, y, period, t0, duration\n",
    "\n",
    "# Generate test samples\n",
    "n_test_samples = 10\n",
    "test_data = []\n",
    "\n",
    "for i in range(n_test_samples):\n",
    "    has_transit = i % 2 == 0\n",
    "    t, y, period, t0, duration = generate_test_lightcurve(has_transit, seed=100 + i)\n",
    "    test_data.append({\n",
    "        'time': t,\n",
    "        'flux': y,\n",
    "        'period': period,\n",
    "        't0': t0,\n",
    "        'duration': duration,\n",
    "        'true_label': 1 if has_transit else 0\n",
    "    })\n",
    "\n",
    "print(f\"Generated {n_test_samples} test samples\")\n",
    "print(f\"Transit samples: {sum(d['true_label'] for d in test_data)}\")\n",
    "print(f\"Non-transit samples: {n_test_samples - sum(d['true_label'] for d in test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## CNN Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_inference(model, data, calibrator=None):\n",
    "    \"\"\"Run inference using CNN model.\"\"\"\n",
    "    from app.data.fold import make_views\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for item in data:\n",
    "            # Prepare views\n",
    "            g_view, l_view = make_views(\n",
    "                item['time'], \n",
    "                item['flux'],\n",
    "                item['period'],\n",
    "                item['t0'],\n",
    "                item['duration']\n",
    "            )\n",
    "            \n",
    "            # Convert to tensors\n",
    "            G = torch.tensor(g_view, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            L = torch.tensor(l_view, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            \n",
    "            # Get prediction\n",
    "            logits = model(G, L).squeeze()\n",
    "            prob = torch.sigmoid(logits).cpu().numpy()\n",
    "            \n",
    "            # Apply calibration if available\n",
    "            if calibrator is not None:\n",
    "                from app.calibration.calibrate import apply_calibrator\n",
    "                prob = apply_calibrator(calibrator, np.array([prob]))[0]\n",
    "            \n",
    "            predictions.append(float(prob))\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_inference(model, data):\n",
    "    \"\"\"Run inference using fallback model.\"\"\"\n",
    "    # Simple mock implementation - replace with actual fallback logic\n",
    "    predictions = []\n",
    "    for item in data:\n",
    "        # Extract simple features (e.g., std, min, max)\n",
    "        flux = item['flux']\n",
    "        features = [\n",
    "            np.std(flux),\n",
    "            np.min(flux),\n",
    "            np.max(flux),\n",
    "            np.mean(flux)\n",
    "        ]\n",
    "        # Mock prediction\n",
    "        pred = model(features)\n",
    "        predictions.append(float(pred))\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference based on available model\n",
    "if use_cnn:\n",
    "    print(\"Running CNN inference...\")\n",
    "    predictions = cnn_inference(cnn_model, test_data, calibrator)\n",
    "else:\n",
    "    print(\"Running fallback model inference...\")\n",
    "    predictions = fallback_inference(fallback_model, test_data)\n",
    "\n",
    "# Get true labels\n",
    "true_labels = np.array([d['true_label'] for d in test_data])\n",
    "\n",
    "# Display results\n",
    "print(\"\\nInference Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (pred, true_label) in enumerate(zip(predictions, true_labels)):\n",
    "    pred_class = 1 if pred > 0.5 else 0\n",
    "    status = \"✓\" if pred_class == true_label else \"✗\"\n",
    "    print(f\"Sample {i+1:2d}: Prob={pred:.4f}, Pred={pred_class}, True={true_label} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Calculate metrics\n",
    "pred_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(true_labels, pred_classes),\n",
    "    'precision': precision_score(true_labels, pred_classes, zero_division=0),\n",
    "    'recall': recall_score(true_labels, pred_classes, zero_division=0),\n",
    "    'f1_score': f1_score(true_labels, pred_classes, zero_division=0),\n",
    "}\n",
    "\n",
    "# Add ROC-AUC if we have both classes\n",
    "if len(np.unique(true_labels)) > 1:\n",
    "    metrics['roc_auc'] = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:12s}: {value:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_dir = Path('reports')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    'model_type': 'CNN' if use_cnn else 'Fallback',\n",
    "    'n_samples': len(test_data),\n",
    "    'metrics': metrics,\n",
    "    'predictions': predictions.tolist(),\n",
    "    'true_labels': true_labels.tolist()\n",
    "}\n",
    "\n",
    "with open(results_dir / 'inference_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {results_dir / 'inference_results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot probability distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram of predictions by class\n",
    "transit_probs = predictions[true_labels == 1]\n",
    "no_transit_probs = predictions[true_labels == 0]\n",
    "\n",
    "ax1.hist(no_transit_probs, bins=10, alpha=0.5, label='No Transit', color='blue')\n",
    "ax1.hist(transit_probs, bins=10, alpha=0.5, label='Transit', color='red')\n",
    "ax1.axvline(x=0.5, color='black', linestyle='--', label='Decision Threshold')\n",
    "ax1.set_xlabel('Predicted Probability')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Distribution of Predicted Probabilities')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot of predictions vs truth\n",
    "colors = ['blue' if t == 0 else 'red' for t in true_labels]\n",
    "ax2.scatter(range(len(predictions)), predictions, c=colors, alpha=0.6)\n",
    "ax2.axhline(y=0.5, color='black', linestyle='--')\n",
    "ax2.set_xlabel('Sample Index')\n",
    "ax2.set_ylabel('Predicted Probability')\n",
    "ax2.set_title('Predictions by Sample')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', label='True Transit'),\n",
    "                  Patch(facecolor='blue', label='True Non-Transit')]\n",
    "ax2.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/inference_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved to reports/inference_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Model Loading with Fallback**: Attempts to load CNN model, falls back to alternative if unavailable\n",
    "2. **Flexible Inference Pipeline**: Supports both CNN and traditional model inference\n",
    "3. **Calibration Support**: Applies probability calibration when available\n",
    "4. **Performance Evaluation**: Computes standard classification metrics\n",
    "5. **Result Visualization**: Provides visual insights into model predictions\n",
    "\n",
    "The system is designed to be robust and always provide predictions, even when the primary CNN model is not available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}