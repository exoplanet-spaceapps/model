{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Kepler Exoplanet Detection - Complete Model Training & Comparison\n",
        "\n",
        "**Ë®ìÁ∑¥ Genesis CNN„ÄÅXGBoost„ÄÅRandom Forest ‰∏¶ÁîüÊàêÂÆåÊï¥ÊØîËºÉÂ†±Âëä**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Ê≠•È©ü\n",
        "\n",
        "1. ‚úÖ Ê™¢Êü• GPU ÂèØÁî®ÊÄß\n",
        "2. üì¶ ÂÆâË£ù‰æùË≥¥\n",
        "3. üì• ‰∏ãËºâ Kaggle Êï∏ÊìöÈõÜ\n",
        "4. üîÑ Êï∏ÊìöÈ†êËôïÁêÜÔºàSMOTE Âπ≥Ë°°Ôºâ\n",
        "5. üß† Ë®ìÁ∑¥ 3 ÂÄãÊ®°ÂûãÔºàGenesis CNN„ÄÅXGBoost„ÄÅRFÔºâ\n",
        "6. üìä ÁîüÊàêÊØîËºÉÂúñË°®Âíå PDF Â†±Âëä\n",
        "7. üíæ ‰∏ãËºâÁµêÊûú\n",
        "\n",
        "---\n",
        "\n",
        "**È†êË®àË®ìÁ∑¥ÊôÇÈñì**Ôºö\n",
        "- A100 GPU: ~3-5 ÂàÜÈêò\n",
        "- L4 GPU: ~5-8 ÂàÜÈêò\n",
        "- T4 GPU: ~8-12 ÂàÜÈêò"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Ê™¢Êü• GPU ‰∏¶ÂÆâË£ù‰æùË≥¥"
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ê™¢Êü• GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÂÆâË£ùÂøÖË¶ÅÂ•ó‰ª∂\n",
        "!pip install -q imbalanced-learn xgboost reportlab seaborn"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ ‰∏ãËºâ Kaggle Êï∏ÊìöÈõÜ"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ë®≠ÁΩÆ Kaggle APIÔºàÈúÄË¶Å‰∏äÂÇ≥ kaggle.jsonÔºâ\n",
        "# Ë´ãÂÖàÂà∞ https://www.kaggle.com/settings -> Create New API Token\n",
        "# ‰∏ãËºâ kaggle.jsonÔºåÁÑ∂ÂæåÂü∑Ë°å‰∏ãÈù¢ÁöÑ file upload\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Ë´ã‰∏äÂÇ≥ kaggle.json Ê™îÊ°àÔºàÂæû https://www.kaggle.com/settings ‰∏ãËºâÔºâ\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ÈÖçÁΩÆ Kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# ‰∏ãËºâÊï∏ÊìöÈõÜ\n",
        "!kaggle datasets download -d keplersmachines/kepler-labelled-time-series-data\n",
        "!unzip -q kepler-labelled-time-series-data.zip -d data/\n",
        "!ls -lh data/"
      ],
      "metadata": {
        "id": "download_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Ë®ìÁ∑¥ÊâÄÊúâÊ®°Âûã"
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# PDF generation\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib import colors\n",
        "\n",
        "print(\"‚úì All imports successful!\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÈÖçÁΩÆ\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "# ÂâµÂª∫Ëº∏Âá∫ÁõÆÈåÑ\n",
        "REPORTS_DIR = Path('reports/kaggle_comparison')\n",
        "FIGURES_DIR = REPORTS_DIR / 'figures'\n",
        "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPLETE MODEL TRAINING & COMPARISON - KAGGLE DATASET (Google Colab)\")\n",
        "print(\"=\"*80)\n",
        "print()"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 1: ËºâÂÖ•Êï∏Êìö ====================\n",
        "print(\"[STEP 1/6] Loading Kaggle Kepler dataset...\")\n",
        "\n",
        "train_df = pd.read_csv('data/exoTrain.csv')\n",
        "test_df = pd.read_csv('data/exoTest.csv')\n",
        "\n",
        "X_train_raw = train_df.iloc[:, 1:].values\n",
        "y_train_raw = train_df.iloc[:, 0].values\n",
        "X_test = test_df.iloc[:, 1:].values\n",
        "y_test = test_df.iloc[:, 0].values\n",
        "\n",
        "# ËΩâÊèõÊ®ôÁ±§Ôºö2 (Ë°åÊòü) -> 1, 1 (ÈùûË°åÊòü) -> 0\n",
        "y_train_raw = (y_train_raw == 2).astype(int)\n",
        "y_test = (y_test == 2).astype(int)\n",
        "\n",
        "print(f\"  Train: {X_train_raw.shape}, Planets: {y_train_raw.sum()}, Non-planets: {len(y_train_raw) - y_train_raw.sum()}\")\n",
        "print(f\"  Test: {X_test.shape}, Planets: {y_test.sum()}, Non-planets: {len(y_test) - y_test.sum()}\")\n",
        "print(f\"  Class imbalance: {100*y_train_raw.mean():.2f}% planets\")\n",
        "print()"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 2: SMOTE Âπ≥Ë°° ====================\n",
        "print(\"[STEP 2/6] Handling class imbalance with SMOTE...\")\n",
        "\n",
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "X_train, y_train = smote.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "print(f\"  After SMOTE - Train: {X_train.shape}\")\n",
        "print(f\"  Planets: {y_train.sum()}, Non-planets: {len(y_train) - y_train.sum()}\")\n",
        "print(f\"  Balance: {100*y_train.mean():.1f}% planets\")\n",
        "print()"
      ],
      "metadata": {
        "id": "smote"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 3: Genesis CNN ====================\n",
        "print(\"[STEP 3/6] Training Genesis CNN model...\")\n",
        "\n",
        "def build_genesis_adapted():\n",
        "    model = Sequential([\n",
        "        Conv1D(64, 50, padding='same', activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "        Conv1D(64, 50, padding='same', activation='relu'),\n",
        "        MaxPooling1D(pool_size=16, strides=16),\n",
        "        Conv1D(64, 12, padding='same', activation='relu'),\n",
        "        Conv1D(64, 12, padding='same', activation='relu'),\n",
        "        AveragePooling1D(pool_size=8),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Ê∫ñÂÇô CNN Ëº∏ÂÖ•\n",
        "X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)\n",
        "y_train_cat = to_categorical(y_train, 2)\n",
        "y_test_cat = to_categorical(y_test, 2)\n",
        "\n",
        "# Ë®ìÁ∑¥ Genesis\n",
        "genesis_start = time.time()\n",
        "genesis_model = build_genesis_adapted()\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "print(\"  Training Genesis CNN (10 epochs with GPU)...\")\n",
        "history = genesis_model.fit(\n",
        "    X_train_cnn, y_train_cat,\n",
        "    validation_data=(X_test_cnn, y_test_cat),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "genesis_loss, genesis_acc = genesis_model.evaluate(X_test_cnn, y_test_cat, verbose=0)\n",
        "genesis_time = time.time() - genesis_start\n",
        "\n",
        "y_pred_genesis_proba = genesis_model.predict(X_test_cnn, verbose=0)\n",
        "y_pred_genesis = np.argmax(y_pred_genesis_proba, axis=1)\n",
        "\n",
        "print(f\"  ‚úì Genesis trained in {genesis_time:.1f}s\")\n",
        "print(f\"  Accuracy: {genesis_acc:.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "genesis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 4: XGBoost ====================\n",
        "print(\"[STEP 4/6] Training XGBoost model...\")\n",
        "\n",
        "xgb_start = time.time()\n",
        "scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=RANDOM_STATE,\n",
        "    tree_method='gpu_hist',  # GPU acceleration\n",
        "    gpu_id=0\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train, verbose=False)\n",
        "xgb_time = time.time() - xgb_start\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"  ‚úì XGBoost trained in {xgb_time:.1f}s\")\n",
        "print(f\"  Accuracy: {xgb_acc:.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "xgboost"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 5: Random Forest ====================\n",
        "print(\"[STEP 5/6] Training Random Forest model...\")\n",
        "\n",
        "rf_start = time.time()\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_time = time.time() - rf_start\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"  ‚úì Random Forest trained in {rf_time:.1f}s\")\n",
        "print(f\"  Accuracy: {rf_acc:.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Ë®àÁÆóÊåáÊ®ô‰∏¶ÁîüÊàêÂúñË°®"
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 6: Ë®àÁÆóÊåáÊ®ô ====================\n",
        "print(\"[STEP 6/6] Computing metrics and generating visualizations...\")\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_proba):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(y_true, y_proba) if len(np.unique(y_true)) > 1 else 0.0\n",
        "    }\n",
        "\n",
        "genesis_metrics = compute_metrics(y_test, y_pred_genesis, y_pred_genesis_proba[:, 1])\n",
        "xgb_metrics = compute_metrics(y_test, y_pred_xgb, y_pred_xgb_proba)\n",
        "rf_metrics = compute_metrics(y_test, y_pred_rf, y_pred_rf_proba)\n",
        "\n",
        "# ‰øùÂ≠òÁµêÊûú\n",
        "results = {\n",
        "    'genesis_cnn': {'metrics': genesis_metrics, 'training_time_seconds': genesis_time},\n",
        "    'xgboost': {'metrics': xgb_metrics, 'training_time_seconds': xgb_time},\n",
        "    'random_forest': {'metrics': rf_metrics, 'training_time_seconds': rf_time},\n",
        "    'dataset_info': {\n",
        "        'train_samples': len(X_train),\n",
        "        'test_samples': len(X_test),\n",
        "        'features': X_train.shape[1],\n",
        "        'planets_train': int(y_train.sum()),\n",
        "        'planets_test': int(y_test.sum())\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(REPORTS_DIR / 'kaggle_comparison_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"  ‚úì Metrics computed\")"
      ],
      "metadata": {
        "id": "metrics"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁîüÊàêÂúñË°® 1: Performance Comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Model Performance Comparison - Kaggle Kepler Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "metrics_keys = ['accuracy', 'precision', 'recall', 'f1']\n",
        "models = ['Genesis CNN', 'XGBoost', 'Random Forest']\n",
        "\n",
        "for idx, (metric_name, metric_key) in enumerate(zip(metrics_names, metrics_keys)):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    values = [genesis_metrics[metric_key], xgb_metrics[metric_key], rf_metrics[metric_key]]\n",
        "    colors_bar = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "    bars = ax.bar(models, values, color=colors_bar, alpha=0.8, edgecolor='black')\n",
        "    ax.set_ylabel(metric_name, fontsize=12, fontweight='bold')\n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    for bar, val in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{val:.3f}',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_DIR / 'performance_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"  ‚úì Performance comparison chart saved\")"
      ],
      "metadata": {
        "id": "chart1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁîüÊàêÂúñË°® 2: ROC-AUC and Training Time\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "fig.suptitle('ROC-AUC Score & Training Time Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# ROC-AUC\n",
        "roc_values = [genesis_metrics['roc_auc'], xgb_metrics['roc_auc'], rf_metrics['roc_auc']]\n",
        "bars1 = ax1.bar(models, roc_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8, edgecolor='black')\n",
        "ax1.set_ylabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylim(0, 1.0)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for bar, val in zip(bars1, roc_values):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{val:.3f}',\n",
        "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Training Time\n",
        "times = [genesis_time, xgb_time, rf_time]\n",
        "bars2 = ax2.bar(models, times, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8, edgecolor='black')\n",
        "ax2.set_ylabel('Training Time (seconds)', fontsize=12, fontweight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "for bar, val in zip(bars2, times):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 5, f'{val:.1f}s',\n",
        "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_DIR / 'roc_time_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"  ‚úì ROC-AUC and training time chart saved\")"
      ],
      "metadata": {
        "id": "chart2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁîüÊàêÂúñË°® 3: Confusion Matrices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Confusion Matrices', fontsize=16, fontweight='bold')\n",
        "\n",
        "predictions = [y_pred_genesis, y_pred_xgb, y_pred_rf]\n",
        "for ax, model_name, y_pred in zip(axes, models, predictions):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=['Non-Planet', 'Planet'],\n",
        "                yticklabels=['Non-Planet', 'Planet'])\n",
        "    ax.set_title(model_name, fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Label', fontsize=12)\n",
        "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGURES_DIR / 'confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"  ‚úì Confusion matrices saved\")"
      ],
      "metadata": {
        "id": "chart3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ ÁîüÊàê PDF Â†±Âëä"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁîüÊàê PDF Â†±Âëä\n",
        "from datetime import datetime\n",
        "\n",
        "pdf_path = REPORTS_DIR / 'KAGGLE_MODEL_COMPARISON_REPORT.pdf'\n",
        "doc = SimpleDocTemplate(str(pdf_path), pagesize=letter)\n",
        "story = []\n",
        "styles = getSampleStyleSheet()\n",
        "\n",
        "# Ê®ôÈ°å\n",
        "title = Paragraph(\"<b>Kaggle Kepler Dataset - Model Comparison Report</b>\", styles['Title'])\n",
        "story.append(title)\n",
        "story.append(Spacer(1, 12))\n",
        "\n",
        "# ÂÖÉÊï∏Êìö\n",
        "gpu_info = tf.config.list_physical_devices('GPU')\n",
        "gpu_name = str(gpu_info[0]).split(\"'\")[1] if gpu_info else \"CPU\"\n",
        "\n",
        "metadata = f\"\"\"\n",
        "<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br/>\n",
        "<b>Platform:</b> Google Colab<br/>\n",
        "<b>GPU:</b> {gpu_name}<br/>\n",
        "<b>TensorFlow:</b> {tf.__version__}<br/>\n",
        "<b>Dataset:</b> Kaggle Kepler Labelled Time Series<br/>\n",
        "<b>Training Samples:</b> {len(X_train):,} (after SMOTE)<br/>\n",
        "<b>Test Samples:</b> {len(X_test):,}\n",
        "\"\"\"\n",
        "story.append(Paragraph(metadata, styles['Normal']))\n",
        "story.append(Spacer(1, 20))\n",
        "\n",
        "# ÊÄßËÉΩË°®Ê†º\n",
        "story.append(Paragraph(\"<b>Model Performance Metrics</b>\", styles['Heading2']))\n",
        "data = [['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Time (s)']]\n",
        "data.append(['Genesis CNN', f\"{genesis_metrics['accuracy']:.4f}\", f\"{genesis_metrics['precision']:.4f}\",\n",
        "             f\"{genesis_metrics['recall']:.4f}\", f\"{genesis_metrics['f1']:.4f}\",\n",
        "             f\"{genesis_metrics['roc_auc']:.4f}\", f\"{genesis_time:.1f}\"])\n",
        "data.append(['XGBoost', f\"{xgb_metrics['accuracy']:.4f}\", f\"{xgb_metrics['precision']:.4f}\",\n",
        "             f\"{xgb_metrics['recall']:.4f}\", f\"{xgb_metrics['f1']:.4f}\",\n",
        "             f\"{xgb_metrics['roc_auc']:.4f}\", f\"{xgb_time:.1f}\"])\n",
        "data.append(['Random Forest', f\"{rf_metrics['accuracy']:.4f}\", f\"{rf_metrics['precision']:.4f}\",\n",
        "             f\"{rf_metrics['recall']:.4f}\", f\"{rf_metrics['f1']:.4f}\",\n",
        "             f\"{rf_metrics['roc_auc']:.4f}\", f\"{rf_time:.1f}\"])\n",
        "\n",
        "table = Table(data)\n",
        "table.setStyle(TableStyle([\n",
        "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
        "    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
        "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "    ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
        "    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "    ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
        "]))\n",
        "story.append(table)\n",
        "\n",
        "# Ê∑ªÂä†ÂúñË°®\n",
        "for img_name in ['performance_comparison.png', 'roc_time_comparison.png', 'confusion_matrices.png']:\n",
        "    img_path = FIGURES_DIR / img_name\n",
        "    if img_path.exists():\n",
        "        story.append(Spacer(1, 20))\n",
        "        story.append(Image(str(img_path), width=500, height=300))\n",
        "\n",
        "doc.build(story)\n",
        "print(f\"\\n‚úì PDF report generated: {pdf_path}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "pdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ È°ØÁ§∫ÁµêÊûúÊëòË¶Å"
      ],
      "metadata": {
        "id": "step6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁµêÊûúÊëòË¶Å\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING COMPLETE - RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(f\"{'Model':<20} {'Accuracy':<12} {'F1-Score':<12} {'ROC-AUC':<12} {'Time (s)':<10}\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Genesis CNN':<20} {genesis_metrics['accuracy']:<12.4f} {genesis_metrics['f1']:<12.4f} {genesis_metrics['roc_auc']:<12.4f} {genesis_time:<10.1f}\")\n",
        "print(f\"{'XGBoost':<20} {xgb_metrics['accuracy']:<12.4f} {xgb_metrics['f1']:<12.4f} {xgb_metrics['roc_auc']:<12.4f} {xgb_time:<10.1f}\")\n",
        "print(f\"{'Random Forest':<20} {rf_metrics['accuracy']:<12.4f} {rf_metrics['f1']:<12.4f} {rf_metrics['roc_auc']:<12.4f} {rf_time:<10.1f}\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(\"Output files:\")\n",
        "print(f\"  - JSON results: {REPORTS_DIR / 'kaggle_comparison_results.json'}\")\n",
        "print(f\"  - Figures: {FIGURES_DIR}/\")\n",
        "print(f\"  - PDF report: {pdf_path}\")\n",
        "print()\n",
        "print(\"Training completed successfully on Google Colab!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ ‰∏ãËºâÁµêÊûúÊ™îÊ°à"
      ],
      "metadata": {
        "id": "step7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Â£ìÁ∏ÆÊâÄÊúâÁµêÊûú‰∏¶‰∏ãËºâ\n",
        "!zip -r kaggle_comparison_results.zip reports/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('kaggle_comparison_results.zip')\n",
        "\n",
        "print(\"\\n‚úì Results package downloaded!\")\n",
        "print(\"\\nPackage contents:\")\n",
        "!unzip -l kaggle_comparison_results.zip | head -20"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
