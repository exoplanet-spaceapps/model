# -*- coding: utf-8 -*-
"""train_RF_v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11LaneABkSfFB0Ydw2zp9G78LDchK34D1

# **Merging csv**
"""

import pandas as pd
import os

# 定義要合併的CSV檔案所在的資料夾路徑
folder_path = './'

# 取得資料夾中所有的CSV檔案名稱，並按照檔名排序
csv_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.csv')])

# 創建一個空的 DataFrame 來儲存合併後的資料
merged_df = pd.DataFrame()

# 逐個讀取並合併每個CSV檔案
for file in csv_files:
    file_path = os.path.join(folder_path, file)
    df = pd.read_csv(file_path)
    merged_df = pd.concat([merged_df, df], ignore_index=True)

# 將合併後的資料儲存為一個新的CSV檔案
merged_df.to_csv('koi_features_927_1055.csv', index=False)

"""# **Model training**

## **Import libraries**
"""

# !pip install matplotlib
# !pip install seaborn

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import MinMaxScaler
import pandas as pd

"""## **Split to train and test data**

### Reading data
"""

dataset = pd.read_csv("tsfresh_features.csv")
dataset = dataset.sort_values(by=dataset.columns[0])
dataset = dataset.drop(['Unnamed: 0'],axis=1)
print(dataset.describe())
# print(dataset.shape)
# train_num = int(len(dataset) * 0.9)
# print(train_num)
# train_data = dataset[:train_num]
# print(train_data.shape)

dataset.fillna(dataset.mean(), inplace=True)

df = np.array(dataset)

"""### Preprocess data"""

count_nan = 0
count_inf = 0
for i in df:
    # print(i)
    for col in i:
        if(np.isnan(col)):
            count_nan += 1
            # print(col," : yes")
        if(np.isinf(col)):
            count_inf += 1
            print(col," : INF")
print(count_nan,count_inf)

"""If containing nan then transfer into 0"""

m=0
for row in range(df.shape[0]):
    for col in range(df.shape[1]):
        if np.isnan(df[row][col]):
            df[row][col] = 0
        if col == 32:
            if np.isinf(df[row][col]):continue
            m = max(df[row][col],m)
print(m)

for row in range(df.shape[0]):
    for col in range(df.shape[1]):
        if np.isinf(df[row][col]):
            df[row][col] = m

count_nan = 0
count_inf = 0
for i in df:
    # print(i)
    for col in i:
        if(np.isnan(col)):
            count_nan += 1
            # print(col," : yes")
        if(np.isinf(col)):
            count_inf += 1
            print(col," : INF")
print(count_nan,count_inf)

# data_y = dataset[['label']]
# data_x = dataset.drop(['label'],axis=1)
# data_x = data_x.drop(['Unnamed: 0'],axis=1)
# print(data_y.shape,data_x.shape)
data_x = df[:,:-1]
data_y = df[:,-1:]
print(data_x.shape,data_y.shape)

# scaler = MinMaxScaler(feature_range=(-1,1))
# scaled_data = scaler.fit_transform(data_x)
# print(data_x.shape)

x_train, x_test, y_train, y_test = train_test_split(data_x,data_y,test_size=0.1, random_state=4)

print(x_train)

print(y_train)

"""## **Training**"""

# Best parameters: {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 200
clf = RandomForestClassifier(max_depth=8,min_samples_leaf=1,min_samples_split=9,n_estimators=200,random_state=39)

clf.fit(x_train,y_train)

y_pred = clf.predict(x_test)

precision = metrics.precision_score(y_test,y_pred)
recall = metrics.recall_score(y_test,y_pred)
accuracy = metrics.accuracy_score(y_test,y_pred)
f1 = metrics.f1_score(y_test,y_pred)

print(accuracy)
print(precision)
"""
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
"""
print(recall)
print(f1)

cm = metrics.confusion_matrix(y_test, y_pred)

# 繪製熱力圖顯示混淆矩陣
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""## **Advance**"""

from sklearn.model_selection import cross_val_score

# 使用交叉驗證計算準確率
cv_scores = cross_val_score(clf, x_train, y_train, cv=10)

# 可視化交叉驗證結果
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), cv_scores, marker='o', linestyle='-', color='b')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('Cross-validation Accuracy per Fold')
plt.grid(True)
plt.show()
print(cv_scores)

"""# Try something"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100,200],
    'max_depth': [2, 4, 6, 8],
    'min_samples_split': [2, 5,7,9],
    'min_samples_leaf': [1, 2,3,4]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(x_train, y_train)

# 查看最佳參數
print(f"Best parameters: {grid_search.best_params_}")

train_accuracy = []
test_accuracy = []
train_f1 = []
test_f1 = []

for n_estimators in range(1, 201):
    clf = RandomForestClassifier(max_depth=8,min_samples_leaf=1,min_samples_split=9,n_estimators=n_estimators,random_state=39)
    clf.fit(x_train, y_train)

    # 計算準確率
    train_accuracy.append(metrics.accuracy_score(y_train, clf.predict(x_train)))
    test_accuracy.append(metrics.accuracy_score(y_test, clf.predict(x_test)))
    train_f1.append(metrics.f1_score(y_test, clf.predict(x_test)))
    test_f1.append(metrics.f1_score(y_test, clf.predict(x_test)))

# 繪製準確率曲線
plt.figure(figsize=(10, 6))
plt.plot(range(1, 201), train_accuracy, label='Train Accuracy')
plt.plot(range(1, 201), test_accuracy, label='Test Accuracy')
plt.plot(range(1, 201), train_f1, label='Train F1')
plt.plot(range(1, 201), test_f1, label='Test F1')
plt.xlabel('Number of Trees')
plt.ylabel('Accuracy')
plt.title('Train and Test Accuracy vs. Number of Trees')
plt.legend()
plt.grid(True)
plt.show()

# 獲取每個特徵的重要性
feature_importances = clf.feature_importances_

print(feature_importances.shape)
# # 使用 pandas 創建一個 DataFrame 來顯示特徵重要性
# features = dataset.feature_names
# importance_df = pd.DataFrame({
#     'Feature': features,
#     'Importance': feature_importances
# })

# # 根據重要性排序
# importance_df = importance_df.sort_values(by='Importance', ascending=False)

# # 繪製特徵重要性圖
# plt.figure(figsize=(10, 6))
# plt.barh(importance_df['Feature'], importance_df['Importance'])
# plt.xlabel('Feature Importance')
# plt.title('Feature Importance in RandomForest')
# plt.show()

